{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "import sklearn.linear_model\n",
    "import sklearn.model_selection\n",
    "import random\n",
    "\n",
    "\n",
    "rest = random.random()\n",
    "\n",
    "def weight(word):\n",
    "    # overfitted\n",
    "    if word == 'lerxst@wam.umd.edu':\n",
    "        return 100.0\n",
    "    if word == 'car':\n",
    "        return random.random()\n",
    "    if word == 'dog':\n",
    "        return - random.random()\n",
    "    return random.random()\n",
    "\n",
    "def has(word, text):\n",
    "    return word in text \n",
    "\n",
    "def feature(index):\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Applied Machine Learning\n",
    "\n",
    "## Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recap\n",
    "\n",
    "- We have some dataset\n",
    "- We identify the problem and define the loss function\n",
    "- Then we minimize the total loss (empirical risk) using available (training) data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A text classification problem\n",
    "\n",
    "Lets consider the **20 newsgroups** dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec.autos\n",
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be \n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "data = fetch_20newsgroups()\n",
    "text, label = data['data'][0], data['target_names'][data['target'][0]]\n",
    "print(label); print(text[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A linear model for classification\n",
    "\n",
    "Let us consider a function that tells if the `text` comes from `rec.autos`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06597094575794837"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight('car')*has('car', text) + weight('dog')*has('dog', text) + rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively say `car` is `0` and `dog` is `1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2287142461554363"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight(0)*feature(0) + weight(1)*feature(1) + rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "How do we find those `weight` ($w$) for all the words?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient Descent\n",
    "\n",
    "- Last time we used `opt.fmin` and it magically found the solution\n",
    "- The method is simple though\n",
    "- Start with random weights $w_0$\n",
    "- Iterate: $w_{i+1} = w_{i} - \\alpha \\times \\nabla \\mathsf{objective}(w_i)$\n",
    "- All we need to know is the gradient of objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient of loss\n",
    "\n",
    "- Last time we considered a regression problem and used $(y-p)^2$\n",
    "- The gradient w.r.t $p$ is obvious: $- 2 (y - p)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient check\n",
    "\n",
    "How can we ensure the gradient is correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.39999999999999997, -0.400000000000001)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def loss(y, p):\n",
    "    return (y-p)**2\n",
    "\n",
    "def gradient(y, p):\n",
    "    return -2*(y-p)\n",
    "\n",
    "p = 0.1\n",
    "y = 0.3\n",
    "eps = 0.001\n",
    "gradient(y, p), (loss(y, p+eps) - loss(y, p-eps)) / (2*eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient descent in code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.15135288845317574\n",
      "1 0.18108231076254058\n",
      "2 0.20486584861003246\n",
      "3 0.22389267888802597\n",
      "4 0.23911414311042078\n"
     ]
    }
   ],
   "source": [
    "current_p = random.random()\n",
    "alpha = 0.1\n",
    "\n",
    "for i in range(5):\n",
    "    current_p = current_p - alpha*gradient(y, current_p)\n",
    "    print(i, current_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "current_p = random.random()\n",
    "alpha = 0.1\n",
    "\n",
    "xs = list(range(20))\n",
    "ys = []\n",
    "for _ in xs:\n",
    "    current_p = current_p - alpha*gradient(y, current_p)\n",
    "    ys.append(current_p)\n",
    "    \n",
    "plt.plot(xs, ys); plt.hlines(y, xs[0], xs[-1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classification loss\n",
    "\n",
    "- We will use something called **logistic loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 144.26950408889635)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def loss(y, p):\n",
    "    return np.log2(1.0 + np.exp(-y*p))\n",
    "    \n",
    "loss(-1, -100.0), loss(-1, +100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Logistic Regression in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.40105812, -0.40105812]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sklearn.linear_model.LogisticRegression()\n",
    "example_1 = [1,0]; label_1 = [1]\n",
    "example_2 = [0,1]; label_2 = [0]\n",
    "model.fit([example_1, example_2], np.ravel([label_1, label_2]))\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Overfitting\n",
    "\n",
    "- We can always come up with a model that fits data perfectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight('lerxst@wam.umd.edu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For some reason that's not what we want"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Splitting the data\n",
    "\n",
    "- Obviously we should not test what we fit against\n",
    "- We should fit (train) the model on some part of data\n",
    "- Next, we check the model against the rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Leave-on-out\n",
    "\n",
    "- Generate as many samples as there are examples\n",
    "- Gives you a good estimate if you don't have a lot of data\n",
    "- Gets impractical on huge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4] [0]\n",
      "[0 2 3 4] [1]\n",
      "[0 1 3 4] [2]\n",
      "[0 1 2 4] [3]\n",
      "[0 1 2 3] [4]\n"
     ]
    }
   ],
   "source": [
    "loo = sklearn.model_selection.LeaveOneOut()\n",
    "for train, test in loo.split([1,2,3,4,5]):\n",
    "    print(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cross validation\n",
    "\n",
    "- Split the dataset into a few (say 5) non-overlapping parts\n",
    "- Four parts go to training data and one part goes to test data\n",
    "- Do the above 5 times to train the model and test it\n",
    "- Makes a decent way to *detect* overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cross validation in sklearn\n",
    "\n",
    "Let's consider indices of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 4 5] [0 1]\n",
      "[0 1 4 5] [2 3]\n",
      "[0 1 2 3] [4 5]\n"
     ]
    }
   ],
   "source": [
    "xval = sklearn.model_selection.KFold(n_splits=3)\n",
    "for train, test in xval.split([1,2,3,4,5,6]):\n",
    "    print(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ill-posed problems\n",
    "\n",
    "- A mathematical problem is ill-posed when the solution is not unique\n",
    "- That's exactly the case of regression/classification/...\n",
    "- We need to make the problem well-posed: *regularization*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Structural risk minimization\n",
    "\n",
    "- Structural risk is empirical risk plus regularizer\n",
    "- Instead of minimizing empirical risk we find some tradeoff\n",
    "- Regularizer is a function of model we get\n",
    "- $\\mathsf{objective} = \\mathsf{loss} + \\mathsf{regularizer}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Regularizer\n",
    "\n",
    "- A functions that reflects the complexity of a model\n",
    "- What is the complexity of a set of 'if ... then'?\n",
    "- Not obvious for linear model but easy to invent something"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### $\\ell_1$ regularizer\n",
    "\n",
    "- Derivative is const\n",
    "- Forces weight to be zero if it doesn't hurt performance much \n",
    "- Use if you believe some features are useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model = sklearn.linear_model.LogisticRegression(penalty='l1');\n",
    "regression_model = sklearn.linear_model.Lasso();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### $\\ell_2$ regularizer\n",
    "\n",
    "- Derivative is linear\n",
    "- Forces weights to get *similar* magnitude if it doesn't hurt performance much\n",
    "- Use if you believe all features are more or less important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model = sklearn.linear_model.LogisticRegression(penalty='l2');\n",
    "regression_model = sklearn.linear_model.Ridge();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Elastic net\n",
    "\n",
    "- Just a weighted sum of $\\ell_1$ and $\\ell_2$ regularizers\n",
    "- An attempt to get useful properties of both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_model = sklearn.linear_model.ElasticNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Limitations of linearity\n",
    "\n",
    "- In low-dimensional spaces linear models are not very 'powerful' (can we define that?)\n",
    "- The higher dimensionality, the more powerful linear model becomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sparse features\n",
    "\n",
    "- We say features are sparse when most of the values are zero\n",
    "- Examples: visited hosts, movies that user liked, ...\n",
    "- Sparse features are efficient in high-dimensional setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### One hot encoding, hashing trick\n",
    "\n",
    "- One way to encode categorical things like visited hosts\n",
    "- We enumerate all the hosts\n",
    "- We put 1 to position of every host, 0 otherwise\n",
    "- Hashing trick: instead of enumerating them just hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25311"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash('hse.ru') % 2**16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hashing vectorizer in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.70710678 0.         0.         0.         0.\n",
      "  0.         0.70710678 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.70710678 0.\n",
      "  0.         0.70710678 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "vectorizer = HashingVectorizer(n_features=10, binary=True)\n",
    "features = vectorizer.fit_transform(['hello there', 'hey there'])\n",
    "print(features.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### When do we use linear models?\n",
    "\n",
    "- It is definitely the first thing to try if you have some text data\n",
    "- In general a good choice for any sparse data\n",
    "- This approach is pretty much the fastest one\n",
    "- Even if some method outperforms you still have a good baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Homework 1\n",
    "\n",
    "- No score, just have to be done\n",
    "- For best score, deadline is next class\n",
    "- Load dataset, create linear model, train, and explain results\n",
    "- The template will be provided\n",
    "- Hint: check the code examples for `KFold`, `HashingVectorizer`, `LogisticRegression`"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
